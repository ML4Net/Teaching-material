{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5aaedf3",
   "metadata": {},
   "source": [
    "<center><b><font size=6>Lab-7 Supervised Learning<b><center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af90b7a",
   "metadata": {},
   "source": [
    "### Objective: build a basic ML pipeline for classification problem:\n",
    "1. **Data segmentation** is used to split the whole dataset into different portions for different purpose - training, validation, and test. Useful link: <a href=\"https://en.wikipedia.org/wiki/Training,_validation,_and_test_data_sets\">Wiki</a>, <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\">sklearn</a>.\n",
    "2. **Usage of classification algorithms using Scikit-learn (sklearn)**: we will use classification algorithms already implemented in sklearn libraries. Useful link: <a href=\"https://en.wikipedia.org/wiki/Statistical_classification\">Wiki</a>, <a href=\"https://scikit-learn.org/stable/auto_examples/classification/index.html#classification\">examples in sklearn</a>.\n",
    "3. **Performance evaluation**: we will also refer to sklearn libraries to use different metrics to evaluate trained model performance. Useful link: <a href=\"https://en.wikipedia.org/wiki/Confusion_matrix\">Wiki</a>, <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html\">sklearn</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d1fd7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import needed python libraries\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8c41f0",
   "metadata": {},
   "source": [
    "### 1. Tutorial - Classification\n",
    "Classification is supervised learning, for which you have labeled data to build/tune/evaluate ML models to classify/predict future samples, helping to make decisions, forecast conditions, identify patterns, etc. \n",
    "\n",
    "\n",
    "\n",
    "Here we use the IRIS dataset as an example to show how you can perform classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c0556ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset of IRIS flowers\n",
    "\n",
    "from sklearn import datasets\n",
    "iris_data = datasets.load_iris()\n",
    "features_iris = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
    "df_iris = pd.DataFrame(iris_data.data, columns = features_iris)\n",
    "df_iris['type'] = 'setosa'\n",
    "df_iris.loc[50:99, 'type'] = 'versicolor'\n",
    "df_iris.loc[100:149, 'type'] = 'virginica'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb59ce2a",
   "metadata": {},
   "source": [
    "### 1.1 Data segmentation\n",
    "\n",
    "For labeled data in possession, you need to split them into training, validation if needed, and test datasets. Training and validation datasets are involved during model training, where training set is used to build the model (learn the parameters), while validation set is used to evaluate the model performance during/after training, avoiding overfitting/underfitting and chosing hyper-parameters. Test set is out of training phase and used to derive the final model performance. \n",
    "\n",
    "For now, we only need training and test datasets. We split data into training and test sets, respectively accounting for 70% and 30% of the sample. Here, we will use **stratified sampling**, which splits the data into two (or more) parts, each having the same proportion of a class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae0ac3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, we need to convert the type of flowers to numerical labels\n",
    "df_iris['label'] = pd.Categorical(df_iris['type']).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fdc9034",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_iris[features_iris], # X\n",
    "    df_iris['label'], # y\n",
    "    stratify = df_iris['label'], # stratify the dataset based on class labels\n",
    "    train_size = 0.7, # percentage of training set\n",
    "    random_state = 15 \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07590f25",
   "metadata": {},
   "source": [
    "### 1.2 ML model usage\n",
    "The way you develop ML models using sklearn is similar for different algorithms, as follows:\n",
    "```python\n",
    "# load the model from sklearn\n",
    "from sklearn.xxx import MODEL\n",
    "\n",
    "# initialize the ML model (includes model and loss)\n",
    "model = MODEL() \n",
    "\n",
    "# train the model by fitting the algorithm based on training set\n",
    "model.fit(X_train, y_train) \n",
    "\n",
    "# use the trained model to make predictions for train and test set\n",
    "preds_train = model.predict(X_train) \n",
    "preds_test = model.predict(X_test) \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e60ee760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we use Gaussian Naive Bayes classifier as an example\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "y_train_pred = gnb.predict(X_train)\n",
    "y_test_pred = gnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc920de",
   "metadata": {},
   "source": [
    "### 1.3 Performance evaluation metrics\n",
    "Instead of building our own functions to evaluate the model performance, we will use sklearn library to do the job. Besides, we can use heatmap to visualize the confusion matrix. These metrics can be evaluated on train/test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "143d37ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        15\n",
      "           1       0.83      1.00      0.91        15\n",
      "           2       1.00      0.80      0.89        15\n",
      "\n",
      "    accuracy                           0.93        45\n",
      "   macro avg       0.94      0.93      0.93        45\n",
      "weighted avg       0.94      0.93      0.93        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report includes\n",
    "# - accuracy\n",
    "# - precision, recall and F1-score for each class (in this case 3 classes)\n",
    "# - averages of precision, recall, and f1-score\n",
    "# - number of samples for each class and in total (support)\n",
    "\n",
    "# Here we show results for test data\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b622be52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get the confusion matrix of test set\n",
    "confusion_test = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "# visualize the confusion matrix\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(confusion_test, cmap='Blues', annot=True, cbar_kws={'label':'Occurrences'})\n",
    "plt.xlabel('Prediction')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe08206",
   "metadata": {},
   "source": [
    "### 2. Exercise - RTP dataset\n",
    "In this exercise, we employ a different dataset, which contains RTP traffic information. The Real-time Transport Protocol (RTP) is a network protocol for delivering real-time audio and video over IP networks. RTP is used in communication and entertainment systems that involve streaming media, such as telephony, video teleconference applications including WebRTC, television services and web-based push-to-talk features. In this laboratory, you will work on traces referred to Webex conference call to perform a classification task. Specifically, the traffic was collected on client side during video-conferencing. The traffic is basically the traces (records) of RTP packets following chronological order. Afterwards, we define successive time windows and aggregate packets in each time window, calculating certain statistics, which can be considered a statistical representation of the traffic in such time window.\n",
    "\n",
    "![](video_conference.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e3948e",
   "metadata": {},
   "source": [
    "### 2.1 Loading the dataset\n",
    "Unzip the RTP_dataset.csv.zip to get the csv dataset describing RTP traffic. Each record describes 1 second of a traffic (packet aggregation) carrying different class of data. Each record reports 95 features including statistics on:\n",
    "- Packet size\n",
    "- Interarrival time*\n",
    "- RTP interarrival time*\n",
    "- Interlength*\n",
    "- Label describing the class of data carried by the flow.\n",
    "<br>*inter statistics are computed based on the difference between the current and previous packet. For example, if packet 1 is received at 30s and packet 2 is received at 31s, the interarrival time between those two will be 1s.\n",
    "\n",
    "Each record (row) belongs to a single class. 3 main classes exist: **Audio, Video, Screen Sharing**. In particular, audio class consists of two sub-classes, **Audio and FEC-Audio**, and video class can be further split in 4 more sub-classes: **High Quality (>=720p), Medium Quality (360p<x<720p), Low Quality (<=360p), and FEC-Video**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ec1f585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>interarrival_std</th>\n",
       "      <th>interarrival_mean</th>\n",
       "      <th>interarrival_min</th>\n",
       "      <th>interarrival_max</th>\n",
       "      <th>interarrival_max_min_diff</th>\n",
       "      <th>interarrival_p10</th>\n",
       "      <th>interarrival_p20</th>\n",
       "      <th>interarrival_p25</th>\n",
       "      <th>interarrival_p30</th>\n",
       "      <th>interarrival_p40</th>\n",
       "      <th>...</th>\n",
       "      <th>rtp_interarrival_max_min_R</th>\n",
       "      <th>rtp_interarrival_kurtosis</th>\n",
       "      <th>rtp_interarrival_skew</th>\n",
       "      <th>rtp_interarrival_moment3</th>\n",
       "      <th>rtp_interarrival_moment4</th>\n",
       "      <th>rtp_interarrival_len_unique_percent</th>\n",
       "      <th>rtp_interarrival_max_value_count_percent</th>\n",
       "      <th>rtp_interarrival_min_max_R</th>\n",
       "      <th>rtp_marker_sum_check</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001927</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.004951</td>\n",
       "      <td>0.014423</td>\n",
       "      <td>0.009472</td>\n",
       "      <td>7.619953e-05</td>\n",
       "      <td>8.045912e-05</td>\n",
       "      <td>8.572698e-05</td>\n",
       "      <td>9.030223e-05</td>\n",
       "      <td>9.799051e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>Audio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000515</td>\n",
       "      <td>0.020009</td>\n",
       "      <td>0.019227</td>\n",
       "      <td>0.021251</td>\n",
       "      <td>0.002024</td>\n",
       "      <td>1.931565e-04</td>\n",
       "      <td>1.953020e-04</td>\n",
       "      <td>1.958430e-04</td>\n",
       "      <td>1.965890e-04</td>\n",
       "      <td>1.985469e-04</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>Audio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.041315</td>\n",
       "      <td>0.019994</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.143393</td>\n",
       "      <td>0.143393</td>\n",
       "      <td>9.536743e-09</td>\n",
       "      <td>9.536743e-09</td>\n",
       "      <td>9.536743e-09</td>\n",
       "      <td>1.907349e-08</td>\n",
       "      <td>4.053116e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.019231</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>Audio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.008119</td>\n",
       "      <td>0.019954</td>\n",
       "      <td>0.000873</td>\n",
       "      <td>0.044432</td>\n",
       "      <td>0.043559</td>\n",
       "      <td>9.701633e-05</td>\n",
       "      <td>1.477895e-04</td>\n",
       "      <td>1.699674e-04</td>\n",
       "      <td>1.779909e-04</td>\n",
       "      <td>1.895509e-04</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>Audio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.018683</td>\n",
       "      <td>0.020117</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.121093</td>\n",
       "      <td>0.121092</td>\n",
       "      <td>1.023531e-05</td>\n",
       "      <td>7.453918e-05</td>\n",
       "      <td>1.209468e-04</td>\n",
       "      <td>1.324451e-04</td>\n",
       "      <td>1.531601e-04</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>Audio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139995</th>\n",
       "      <td>0.000799</td>\n",
       "      <td>0.337698</td>\n",
       "      <td>0.336812</td>\n",
       "      <td>0.338365</td>\n",
       "      <td>0.001553</td>\n",
       "      <td>3.370330e-03</td>\n",
       "      <td>3.372540e-03</td>\n",
       "      <td>3.373646e-03</td>\n",
       "      <td>3.374751e-03</td>\n",
       "      <td>3.376961e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>-2.211840e+08</td>\n",
       "      <td>3.185050e+11</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.488095</td>\n",
       "      <td>3</td>\n",
       "      <td>ScreenSharing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139996</th>\n",
       "      <td>0.159892</td>\n",
       "      <td>0.239946</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.320163</td>\n",
       "      <td>0.320055</td>\n",
       "      <td>9.596729e-04</td>\n",
       "      <td>1.918266e-03</td>\n",
       "      <td>2.397562e-03</td>\n",
       "      <td>2.876859e-03</td>\n",
       "      <td>3.196862e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.671026</td>\n",
       "      <td>-1.148811</td>\n",
       "      <td>-2.524719e+12</td>\n",
       "      <td>6.654528e+16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>ScreenSharing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139997</th>\n",
       "      <td>0.045574</td>\n",
       "      <td>0.040176</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.151814</td>\n",
       "      <td>0.151802</td>\n",
       "      <td>1.705837e-05</td>\n",
       "      <td>3.843689e-05</td>\n",
       "      <td>6.171942e-05</td>\n",
       "      <td>1.125135e-04</td>\n",
       "      <td>2.727780e-04</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>23</td>\n",
       "      <td>ScreenSharing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139998</th>\n",
       "      <td>0.028728</td>\n",
       "      <td>0.325410</td>\n",
       "      <td>0.299745</td>\n",
       "      <td>0.356444</td>\n",
       "      <td>0.056699</td>\n",
       "      <td>3.038041e-03</td>\n",
       "      <td>3.078630e-03</td>\n",
       "      <td>3.098925e-03</td>\n",
       "      <td>3.119220e-03</td>\n",
       "      <td>3.159810e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>0.511144</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>-0.695813</td>\n",
       "      <td>-1.628640e+08</td>\n",
       "      <td>2.163721e+11</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.488856</td>\n",
       "      <td>3</td>\n",
       "      <td>ScreenSharing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139999</th>\n",
       "      <td>0.004189</td>\n",
       "      <td>0.040222</td>\n",
       "      <td>0.032511</td>\n",
       "      <td>0.049401</td>\n",
       "      <td>0.016890</td>\n",
       "      <td>3.474479e-04</td>\n",
       "      <td>3.678946e-04</td>\n",
       "      <td>3.826904e-04</td>\n",
       "      <td>3.873811e-04</td>\n",
       "      <td>3.936524e-04</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>25</td>\n",
       "      <td>ScreenSharing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140000 rows Ã— 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        interarrival_std  interarrival_mean  interarrival_min  \\\n",
       "0               0.001927           0.010000          0.004951   \n",
       "1               0.000515           0.020009          0.019227   \n",
       "2               0.041315           0.019994          0.000000   \n",
       "3               0.008119           0.019954          0.000873   \n",
       "4               0.018683           0.020117          0.000001   \n",
       "...                  ...                ...               ...   \n",
       "139995          0.000799           0.337698          0.336812   \n",
       "139996          0.159892           0.239946          0.000108   \n",
       "139997          0.045574           0.040176          0.000012   \n",
       "139998          0.028728           0.325410          0.299745   \n",
       "139999          0.004189           0.040222          0.032511   \n",
       "\n",
       "        interarrival_max  interarrival_max_min_diff  interarrival_p10  \\\n",
       "0               0.014423                   0.009472      7.619953e-05   \n",
       "1               0.021251                   0.002024      1.931565e-04   \n",
       "2               0.143393                   0.143393      9.536743e-09   \n",
       "3               0.044432                   0.043559      9.701633e-05   \n",
       "4               0.121093                   0.121092      1.023531e-05   \n",
       "...                  ...                        ...               ...   \n",
       "139995          0.338365                   0.001553      3.370330e-03   \n",
       "139996          0.320163                   0.320055      9.596729e-04   \n",
       "139997          0.151814                   0.151802      1.705837e-05   \n",
       "139998          0.356444                   0.056699      3.038041e-03   \n",
       "139999          0.049401                   0.016890      3.474479e-04   \n",
       "\n",
       "        interarrival_p20  interarrival_p25  interarrival_p30  \\\n",
       "0           8.045912e-05      8.572698e-05      9.030223e-05   \n",
       "1           1.953020e-04      1.958430e-04      1.965890e-04   \n",
       "2           9.536743e-09      9.536743e-09      1.907349e-08   \n",
       "3           1.477895e-04      1.699674e-04      1.779909e-04   \n",
       "4           7.453918e-05      1.209468e-04      1.324451e-04   \n",
       "...                  ...               ...               ...   \n",
       "139995      3.372540e-03      3.373646e-03      3.374751e-03   \n",
       "139996      1.918266e-03      2.397562e-03      2.876859e-03   \n",
       "139997      3.843689e-05      6.171942e-05      1.125135e-04   \n",
       "139998      3.078630e-03      3.098925e-03      3.119220e-03   \n",
       "139999      3.678946e-04      3.826904e-04      3.873811e-04   \n",
       "\n",
       "        interarrival_p40  ...  rtp_interarrival_max_min_R  \\\n",
       "0           9.799051e-05  ...                    0.500000   \n",
       "1           1.985469e-04  ...                    0.500000   \n",
       "2           4.053116e-08  ...                    0.500000   \n",
       "3           1.895509e-04  ...                    0.500000   \n",
       "4           1.531601e-04  ...                    0.500000   \n",
       "...                  ...  ...                         ...   \n",
       "139995      3.376961e-03  ...                    0.511905   \n",
       "139996      3.196862e-03  ...                    1.000000   \n",
       "139997      2.727780e-04  ...                    0.500000   \n",
       "139998      3.159810e-03  ...                    0.511144   \n",
       "139999      3.936524e-04  ...                    0.500000   \n",
       "\n",
       "        rtp_interarrival_kurtosis  rtp_interarrival_skew  \\\n",
       "0                       -3.000000               0.000000   \n",
       "1                       -3.000000               0.000000   \n",
       "2                       -3.000000               0.000000   \n",
       "3                       -3.000000               0.000000   \n",
       "4                       -3.000000               0.000000   \n",
       "...                           ...                    ...   \n",
       "139995                  -1.500000              -0.707107   \n",
       "139996                  -0.671026              -1.148811   \n",
       "139997                  -3.000000               0.000000   \n",
       "139998                  -1.500000              -0.695813   \n",
       "139999                  -3.000000               0.000000   \n",
       "\n",
       "        rtp_interarrival_moment3  rtp_interarrival_moment4  \\\n",
       "0                   0.000000e+00              0.000000e+00   \n",
       "1                   0.000000e+00              0.000000e+00   \n",
       "2                   0.000000e+00              0.000000e+00   \n",
       "3                   0.000000e+00              0.000000e+00   \n",
       "4                   0.000000e+00              0.000000e+00   \n",
       "...                          ...                       ...   \n",
       "139995             -2.211840e+08              3.185050e+11   \n",
       "139996             -2.524719e+12              6.654528e+16   \n",
       "139997              0.000000e+00              0.000000e+00   \n",
       "139998             -1.628640e+08              2.163721e+11   \n",
       "139999              0.000000e+00              0.000000e+00   \n",
       "\n",
       "        rtp_interarrival_len_unique_percent  \\\n",
       "0                                  0.010000   \n",
       "1                                  0.020000   \n",
       "2                                  0.019231   \n",
       "3                                  0.020000   \n",
       "4                                  0.021739   \n",
       "...                                     ...   \n",
       "139995                             0.666667   \n",
       "139996                             1.000000   \n",
       "139997                             0.043478   \n",
       "139998                             1.000000   \n",
       "139999                             0.040000   \n",
       "\n",
       "        rtp_interarrival_max_value_count_percent  rtp_interarrival_min_max_R  \\\n",
       "0                                       1.000000                    0.500000   \n",
       "1                                       1.000000                    0.500000   \n",
       "2                                       1.000000                    0.500000   \n",
       "3                                       1.000000                    0.500000   \n",
       "4                                       1.000000                    0.500000   \n",
       "...                                          ...                         ...   \n",
       "139995                                  0.666667                    0.488095   \n",
       "139996                                  0.250000                    0.000000   \n",
       "139997                                  1.000000                    0.500000   \n",
       "139998                                  0.333333                    0.488856   \n",
       "139999                                  1.000000                    0.500000   \n",
       "\n",
       "        rtp_marker_sum_check          label  \n",
       "0                          0          Audio  \n",
       "1                          0          Audio  \n",
       "2                          0          Audio  \n",
       "3                          0          Audio  \n",
       "4                          0          Audio  \n",
       "...                      ...            ...  \n",
       "139995                     3  ScreenSharing  \n",
       "139996                     3  ScreenSharing  \n",
       "139997                    23  ScreenSharing  \n",
       "139998                     3  ScreenSharing  \n",
       "139999                    25  ScreenSharing  \n",
       "\n",
       "[140000 rows x 96 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"RTP_dataset.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac3650a",
   "metadata": {},
   "source": [
    "### 2.2 Binary classification\n",
    "From now on, we focus on two major classes, **Video** and **Audio**, and you need to develop ML pipeline to classify the traffic based on statistical features. Specifically, you will perform the following steps:\n",
    "- Data preprocessing\n",
    "- Model development (perform ERM with an algorithm)\n",
    "- Performance evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0eab26",
   "metadata": {},
   "source": [
    "### 2.2.1 Dataset preprocessing - Data split and standardization\n",
    "- Extract data only associated to the aforementioned classes.\n",
    "- For an individual class, assign a numerical label (0 to Video and 1 to Audio).\n",
    "- Split the whole dataset into training and test. Stratify the split, keeping the 70/30 proportion (i.e., the training dataset contains the 70% of the sample per label, the test contains the remaining 30% per label).\n",
    "- After the splitting, standardize the data (features). Fit the StandardScaler only on the training set and then transform both the training and test sets. From now on, you will use the same standardize datasets for all the experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff3ad91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This part is provided\n",
    "# You can simply run this cell\n",
    "\n",
    "# extract data from Video and Audio\n",
    "# we have to perform a copy of the dataset otherwise we will modify the original dataset\n",
    "\n",
    "video  = ['FEC-Video', 'HighQ', 'LowQ', 'MediumQ']\n",
    "audio  = ['Audio', 'FEC-Audio']\n",
    "screen = ['ScreenSharing']\n",
    "\n",
    "video_data  = df[df[\"label\"].isin(video)].copy()\n",
    "audio_data  = df[df[\"label\"].isin(audio)].copy()\n",
    "\n",
    "video_data[\"binary_label\"]=0\n",
    "audio_data[\"binary_label\"]=1\n",
    "\n",
    "video_data = video_data.drop(\"label\",axis=1)\n",
    "audio_data = audio_data.drop(\"label\",axis=1)\n",
    "\n",
    "binary_dataset = pd.concat([video_data, audio_data])\n",
    "\n",
    "# prepare the new dataset\n",
    "# get the X and y from the dataset\n",
    "X = binary_dataset.drop(columns=['binary_label']).to_numpy()\n",
    "y = binary_dataset[['binary_label']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1cf5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here\n",
    "\n",
    "# run stratified training-test splitting using train_test_split\n",
    "# TODO\n",
    "\n",
    "# standardize data using StandardScaler\n",
    "# TODO (your final output of features in training/test set should be numpy array with shape of [n_samples, n_features])\n",
    "X_train_s = ...\n",
    "X_test_s = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff6a273",
   "metadata": {},
   "source": [
    "### 2.2.2 Dataset preprocessing - Removal of correlated features\n",
    "- For the training set, compute and display the correlation matrix between the features (refer to lab 2 for details).\n",
    "- Remove strongly correlated features from both training and test sets, i.e., features having a correlation > 0.8. Note that a feature may be strongly correlated with many others.\n",
    "    - How many correlated features you have to remove?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280530a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here everything is provided\n",
    "# The input here is the output required from previous steps\n",
    "# Just execute this and the following cells to check correlation matrix and remove correlated features\n",
    "\n",
    "# compute the correlation matrix\n",
    "columns= [i for i in range(X_train_s.shape[1])]\n",
    "df_tmp = pd.DataFrame(X_train_s, columns=columns)\n",
    "correlation_matrix = df_tmp.corr().abs()\n",
    "\n",
    "# display the heatmap\n",
    "plt.figure()\n",
    "sns.heatmap(correlation_matrix, cmap='Blues', vmin=0.8, vmax=1, cbar_kws={'label':'Correlation'})\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Feature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918ec8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract features having a correlation > 0.8\n",
    "c = correlation_matrix[correlation_matrix>0.8]\n",
    "s = c.unstack()\n",
    "so = s.sort_values(ascending=False).reset_index()\n",
    "\n",
    "# get strongly correlatead features removing pairs having correlation = 1 because of the diagonal, i.e., correlation between one feature and itself\n",
    "so = so[(so[0].isnull()==False) & (so[\"level_0\"] != so[\"level_1\"])]\n",
    "\n",
    "to_be_deleted = []\n",
    "candidates = list(so[\"level_0\"])\n",
    "\n",
    "# get the unique set of features to be deleted. Notice that we discard one feature per time considering the case where a feature is strongly correlated with multiple features\n",
    "subset_so = so\n",
    "for candidate in candidates:\n",
    "    if (candidate in list(subset_so[\"level_0\"])): \n",
    "        to_be_deleted.append(candidate)\n",
    "        subset_so = subset_so[(subset_so[\"level_0\"] != candidate) & (subset_so[\"level_1\"] != candidate)]\n",
    "\n",
    "# to_be_deleted contains the index of columns that you need to remove from both training and test sets\n",
    "print(len(to_be_deleted), 'features are removed')\n",
    "\n",
    "# remove the correlated features from bot sets\n",
    "\n",
    "# Create a mask for the columns to keep\n",
    "columns_to_keep = np.ones(X_train_s.shape[1], dtype=bool)\n",
    "columns_to_keep[to_be_deleted] = False\n",
    "\n",
    "# Use the mask to select only the columns to keep\n",
    "X_train_s = X_train_s[:, columns_to_keep]\n",
    "X_test_s = X_test_s[:, columns_to_keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d2ea79",
   "metadata": {},
   "source": [
    "### 2.2.3 Model development\n",
    "- Refer to the following 3 algorithms and train the models with predefined parameters:\n",
    "    - k-Nearest Neighbors (k-NN) (<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\">sklearn</a>), with parameters of ``n_neighbors=3``.\n",
    "    - Logistic Regression (LR) (<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression\">sklearn</a>), with parameters of ``max_iter=150``.\n",
    "    - Random Forest (RF) (<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier\">sklearn</a>), with parameters of ``n_estimators=30``.\n",
    "  \n",
    "    Explain how each parameter will affect the algorithm\n",
    "- After the model training, use the obtained hypothesis to obtain predictions not only for test set but also for training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d79fc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8404d16e",
   "metadata": {},
   "source": [
    "### 2.2.4 Performance evaluation\n",
    "- Now you should have derived 3 sets of predictions for both training and test sets for all models. Evaluate all the 6 predictions, computing and displaying numerical metrics (classification report) and confusion matrix.\n",
    "- Answering the following questions:\n",
    "    - Which model produces the best performance? Why do you think so?\n",
    "    - For each model, which class is better classified? Are they different among models?\n",
    "    - For each model, do you observe the phenomenon of overfitting or underfitting? Why do you think so?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4439fe5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe29141",
   "metadata": {},
   "source": [
    "### 2.3 Regression analysis\n",
    "Here we intend to investigate the possibility of representing a certain feature through other features by performing a regression analysis. In other words, we may find a relationship between a feature and the others. Specifically, we focus on `interarrival_std`, and you need to do the following:\n",
    "- Refer to the original dataset and remove the correlated features as you have done previously.\n",
    "- Randomly split the dataset into training and test set (70/30 and no need of stratification), and standardize the dataset as you have done previously.\n",
    "- Refer to linear regression and decision tree regressor, by training scikit-learn models with default configuration. Documentations:  <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\">Linear regression</a> and <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html#sklearn.tree.DecisionTreeRegressor\">Decision tree regressor</a>.\n",
    "- Make predictions for both of training and test sets.\n",
    "- Output performance metrics for both sets and for both models by calculating Mean Squared Error (MSE) and the Mean Absolute Error (MAE). There're also scikit-learn library doing the job. Answer the following:\n",
    "    - Do you observe overfitting or under-fitting?\n",
    "    - Which model performs better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3c4c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
