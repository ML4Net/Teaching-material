{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3b708e6",
   "metadata": {},
   "source": [
    "<center><b><font size=6>Lab-6 A classifier from scratch<b><center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632f4cc1",
   "metadata": {},
   "source": [
    "### Objective: Implement, use and evaluate a classifier (without using specific libraries such as sklearn)\n",
    "1. **Logistic regression** is a binary classification method that maps a linear combination of parameters and variables into two possible classes. Here, you will implement the logistic regression from scratch to better understand how an ML algorithm works. Useful link: <a href=\"https://en.wikipedia.org/wiki/Logistic_regression\">Wiki</a>.\n",
    "2. **Performance evaluation metrics** are needed to evaluate the outcome of prediction with respect to true labels. Here, you will implement confusion matrix, accuracy, precision, recall and F-measure. Useful link: <a href=\"https://en.wikipedia.org/wiki/Confusion_matrix\">Wiki</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf6be16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import needed python libraries\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3ca305",
   "metadata": {},
   "source": [
    "### 1. Dataset - TCP logs\n",
    "The dataset contains traffic information generated by an open-source passive network monitoring tool, namely **tstat**. It automates the collection of packet statistics of traffic aggregates, using real-time monitoring features. Being a passive tool, the typical usage scenario is live monitoring of Internet links, in which all transmitted packets are observed. In case of TCP, Tstat identifies a new flow start when it observes a TCP three-way handshake. Similarly, it identifies a TCP flow end either when it sees the TCP connection teardown, or when it doesnâ€™t observe packets for some time (idle time). A flow is defined by a unique link between the sender and receiver, e.g., a tuple of <em>(IP_Protocol_Type, IP_Source_Address, Source_Port, IP_Destination_Address, Destination_Port)</em>. For a specific flow, tstat calculates a number of statistics of all the packets transmitted over this flow, and then generate a log for such flow with multiple attributes (statistics). A log file is arranged as a simple table where each column is associated to specific information and each row reports the flow during a connection. The log information is a summary of the flow properties. For instance, in the TCP log we can find columns like the starting time of a TCP connection, its duration, the number of sent and received packets, the observed Round Trip Time.\n",
    "![](tstat.png)\n",
    "\n",
    "In this lab, since the focus is on the development of logistic regression from scratch, we only consider a portion of the dataset for simplicity. The data can be found in `log_tcp_part.csv`, in which there are multiple columns, the last one is the class label, indicating the flow is from either **google** or **youtube**, and the rest are features. Your job is a binary classification task to classify the domain of each flow (row) **from scratch**, including:\n",
    "- Build a logistic regression model,\n",
    "- Evaluate the performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04aaa18f",
   "metadata": {},
   "source": [
    "1. Load the dataset.\n",
    "2. Get the list of features (columns 1 to 10).\n",
    "3. Add a new column and assign numerical class labels of -1 and 1 to google and youtube.\n",
    "4. Answering the following questions:\n",
    "    - How many features do we have?\n",
    "    - How many samples do we have in total?\n",
    "    - How many samples do we have for each class? Are they similar?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d34be47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"log_tcp_part.csv\")\n",
    "features = df.columns.values[:-1]\n",
    "df.loc[df['class']=='google', 'label'] = -1\n",
    "df.loc[df['class']=='youtube', 'label'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a8caf0",
   "metadata": {},
   "source": [
    "### 2. Implement your logistic regression learning algorithm\n",
    "Here you will need to construct a class in which you need to define two functions besides the class initialization:\n",
    "- `fit`. In this method you will perform ERM. Learn the parameters of the model (i.e., the hypothesis h) from training with gradient descent\n",
    "- `predict`. In this method given one  sample x (or more) you will perform the inference $sign(h(x))$ to obtain class labels.\n",
    "\n",
    "Hints:\n",
    "\n",
    "- The linear function used in the logistic regression is the following: $h(x)=w^T x +b $, where b is a scalar bias.\n",
    "- Logistic loss: $L((x,y),h)=\\log(1+e^{-y h(x)})$\n",
    "- ERM: $\\min_{w,b} f(w,b)=\\frac{1}{m}\\sum_{i=1}^{m} \\log(1+e^{-y^{(i)} h(x^{(i)})})$\n",
    "- Gradient for weight: $\\nabla_w f(w,b) = \\frac{1}{m} \\sum_i \\frac{-y^{(i)}x^{(i)}}{(1+e^{+y^{(i)}h(x^{(i)})})}$\n",
    "- Gradient for bias: $\\nabla_b f(w,b)= \\frac{1}{m} \\sum_i \\frac{-y^{(i)}}{(1+e^{+y^{(i)}h(x^{(i)})})}$\n",
    "- Update the parameters: $w \\leftarrow w - \\alpha \\nabla w$, $b \\leftarrow b - \\alpha  \\nabla b$\n",
    "\n",
    "Notice that the sigmoid function $f(z) = \\frac{1}{1 + e^{-z}}$ appears multiple times. You can write also a method for the sigmoid function to help you in the computation. By considering f(z), the gradients rewrite as:\n",
    "\n",
    "- Gradient for weight: $\\nabla_w f(w,b) = \\frac{1}{m} \\sum_i (-y^{(i)}x^{(i)})({f(-y^{(i)} h(x^{(i)})}))  $\n",
    "- Gradient for bias: $\\nabla_b f(w,b) = \\frac{1}{m} \\sum_i (-y^{(i)})({f(-y^{(i)} h(x^{(i)})}))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3db2f7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, learning_rate, num_iterations):\n",
    "        # initialize your learning rate and number of iterations\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_iterations = num_iterations\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        # calculate the sigmoid function\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Initialize weights and bias\n",
    "        # weights should should have the same length of features, you can use np.zeros() to initialize a 0 vector\n",
    "        # bias is a scaler, you can also choose 0\n",
    "        self.weights = np.zeros(X.shape[1])\n",
    "        self.bias = 0\n",
    "        \n",
    "        m = X.shape[0]\n",
    "\n",
    "        for i in range(self.num_iterations):\n",
    "            # Compute linear model output \n",
    "            linear_model_output=np.dot(X, self.weights) + self.bias\n",
    "            # Compute the sigmoid of the output elementwise multiplied by label y\n",
    "            sigmoid_output = self.sigmoid(-linear_model_output*y) \n",
    "\n",
    "            # Compute gradients for weights and bias\n",
    "            dw= (1/m) *  np.dot(X.T, -y*sigmoid_output)\n",
    "            db = (1/m) * np.sum(-y*sigmoid_output)\n",
    "\n",
    "            # Update parameters\n",
    "            self.weights -= self.learning_rate * dw\n",
    "            self.bias -= self.learning_rate * db\n",
    "\n",
    "    def predict(self, X):\n",
    "        # get the prediction by obtaining the sign of the linear model\n",
    "        predictions = np.sign(np.dot(X, self.weights) + self.bias)\n",
    "        \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f147a4",
   "metadata": {},
   "source": [
    "### 3. Use the model\n",
    "- Initialize your model with predefined learning rate of `0.1` and iterations of `100`.\n",
    "- Fit your model with features and targets.\n",
    "- Get the prediction with features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb157e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pandas/core/arraylike.py:364: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "log_reg = LogisticRegression(learning_rate=0.1, num_iterations=100)\n",
    "log_reg.fit(df[features].values, df['label']) \n",
    "predictions = log_reg.predict(df[features].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e678cfd",
   "metadata": {},
   "source": [
    "### 4. Model evaluation\n",
    "With predicted class labels and ground truths, we now evaluate the model performance through confusion matrix and numerical metrics. Specifically, you need to derive the following:\n",
    "- Confusion matrix - Note that, you should indicate the corresponding quantity of each element in the table. Here positive is class 1 and negative is class -1:\n",
    "\\begin{array}{|c|c|c|}\n",
    "\\hline\n",
    " & \\textbf{Predicted Positive} & \\textbf{Predicted Negative} \\\\\n",
    "\\hline\n",
    "\\textbf{Actual Positive} & \\text{True Positive (TP)} & \\text{False Negative (FN)} \\\\\n",
    "\\hline\n",
    "\\textbf{Actual Negative} & \\text{False Positive (FP)} & \\text{True Negative (TN)} \\\\\n",
    "\\hline\n",
    "\\end{array}\n",
    "- Precision of each class and the average value:\n",
    "$\\frac{\\text{True Positive (TP)}}{\\text{True Positive (TP) + False Positive (FP)}}$\n",
    "- Recall of each class and the average value:\n",
    "$\\frac{\\text{True Positive (TP)}}{\\text{True Positive (TP) + False Negative (FN)}}$\n",
    "- F1-score of each class and the average value:\n",
    "$F_1 = \\frac{2 \\times \\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}$\n",
    "- Accuracy:\n",
    "$\\frac{\\text{True Positive (TP) + True Negative (TN)}}{\\text{True Positive (TP) + True Negative (TN) + False Positive (FP) + False Negative (FN)}}$\n",
    "- Answering the following questions:\n",
    "    - Do you have same performance between classes? If not, which one performs better?\n",
    "    - Change the parameters of learning rate or number of iterations. Do you have same performance? Better or Worse? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d11da4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluation(y_true, y_pred):\n",
    "    # Confusion Matrix\n",
    "    TP = sum((y_true[i] == 1) and (y_pred[i] == 1) for i in range(len(y_true)))\n",
    "    FN = sum((y_true[i] == 1) and (y_pred[i] == -1) for i in range(len(y_true)))\n",
    "    FP = sum((y_true[i] == -1) and (y_pred[i] == 1) for i in range(len(y_true)))\n",
    "    TN = sum((y_true[i] == -1) and (y_pred[i] == -1) for i in range(len(y_true)))\n",
    "\n",
    "    # Metrics for Class 1\n",
    "    precision_pos = TP / (TP + FP) if TP + FP != 0 else 0\n",
    "    recall_pos = TP / (TP + FN) if TP + FN != 0 else 0\n",
    "    f1_pos = 2 * (precision_pos * recall_pos) / (precision_pos + recall_pos) if precision_pos + recall_pos != 0 else 0\n",
    "\n",
    "    # Metrics for Class -1\n",
    "    precision_neg = TN / (TN + FN) if TN + FN != 0 else 0\n",
    "    recall_neg = TN / (TN + FP) if TN + FP != 0 else 0\n",
    "    f1_neg = 2 * (precision_neg * recall_neg) / (precision_neg + recall_neg) if precision_neg + recall_neg != 0 else 0\n",
    "\n",
    "    # Accuracy\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "\n",
    "    # Average Values\n",
    "    avg_precision = (precision_pos + precision_neg) / 2\n",
    "    avg_recall = (recall_pos + recall_neg) / 2\n",
    "    avg_f1 = (f1_pos + f1_neg) / 2\n",
    "\n",
    "    # Convert results to DataFrame\n",
    "    df_metrics = pd.DataFrame({\n",
    "        \"precision\": [precision_pos, precision_neg, avg_precision],\n",
    "        \"recall\": [recall_pos, recall_neg, avg_recall],\n",
    "        \"f1-score\": [f1_pos, f1_neg, avg_f1],\n",
    "        \"accuracy\": [accuracy, accuracy, accuracy]\n",
    "    }, index=[\"1\", \"-1\", \"average\"])\n",
    "\n",
    "    df_confusion = pd.DataFrame({\n",
    "        \"1_predicted\": [TP, FP],\n",
    "        \"-1_predicted\": [FN, TN]\n",
    "    }, index=[\"1_actual\", \"-1_actual\"])\n",
    "\n",
    "    return df_confusion, df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72a3b862",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_confusion, df_metrics = model_evaluation(df['label'].values, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15305634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1_predicted</th>\n",
       "      <th>-1_predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1_actual</th>\n",
       "      <td>6729</td>\n",
       "      <td>3271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-1_actual</th>\n",
       "      <td>2493</td>\n",
       "      <td>7507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           1_predicted  -1_predicted\n",
       "1_actual          6729          3271\n",
       "-1_actual         2493          7507"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa939138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.729668</td>\n",
       "      <td>0.6729</td>\n",
       "      <td>0.700135</td>\n",
       "      <td>0.7118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>0.696511</td>\n",
       "      <td>0.7507</td>\n",
       "      <td>0.722591</td>\n",
       "      <td>0.7118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average</th>\n",
       "      <td>0.713090</td>\n",
       "      <td>0.7118</td>\n",
       "      <td>0.711363</td>\n",
       "      <td>0.7118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         precision  recall  f1-score  accuracy\n",
       "1         0.729668  0.6729  0.700135    0.7118\n",
       "-1        0.696511  0.7507  0.722591    0.7118\n",
       "average   0.713090  0.7118  0.711363    0.7118"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147929b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874611f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
